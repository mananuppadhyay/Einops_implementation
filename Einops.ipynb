{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBYgj7dt1JSy2l0OQ1t8Xg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mananuppadhyay/einops_implementation/blob/main/Einops.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "8TnGFmBfo-cH"
      },
      "outputs": [],
      "source": [
        "import einops\n",
        "import torch\n",
        "from functools import reduce\n",
        "import operator\n",
        "import re\n",
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "from typing import List, Dict, Tuple, Any, Union, Optional, Set\n",
        "\n",
        "\n",
        "class EinopsManan:\n",
        "    def parse_lr(self, pattern: str) -> Tuple[List[str], List[str]]:\n",
        "        \"\"\"\n",
        "        Parse the left and right sides of an einops pattern string.\n",
        "\n",
        "        Args:\n",
        "            pattern: A string in the format 'left -> right' where left and right\n",
        "                     represent the input and output tensor specifications.\n",
        "\n",
        "        Returns:\n",
        "            A tuple containing two lists:\n",
        "            - left_tokens: The tokenized left side of the pattern.\n",
        "            - right_tokens: The tokenized right side of the pattern.\n",
        "\n",
        "        Example:\n",
        "            For pattern \"b c (h w) -> b h w c\", returns\n",
        "            (['b', 'c', '(h w)'], ['b', 'h', 'w', 'c'])\n",
        "        \"\"\"\n",
        "        left, right = pattern.split('->')\n",
        "        token_pattern = r'\\.\\.\\.|\\w+|\\([\\w\\s]+\\)'\n",
        "        left_tokens = re.findall(token_pattern, left.strip())\n",
        "        right_tokens = re.findall(token_pattern, right.strip())\n",
        "        return left_tokens, right_tokens\n",
        "\n",
        "    def create_idx_mapping(self, l_expanded: List[str], r_expanded: List[str]) -> Tuple[Dict[str, int], Dict[str, int]]:\n",
        "        \"\"\"\n",
        "        Create index mappings for the expanded left and right token lists.\n",
        "\n",
        "        Args:\n",
        "            l_expanded: The expanded list of tokens from the left side of the pattern.\n",
        "            r_expanded: The expanded list of tokens from the right side of the pattern.\n",
        "\n",
        "        Returns:\n",
        "            A tuple containing two dictionaries:\n",
        "            - mp_l: Maps each variable in l_expanded to its index.\n",
        "            - mp_r: Maps each variable in r_expanded to its index.\n",
        "        \"\"\"\n",
        "        mp_l = {var: i for i, var in enumerate(l_expanded)}\n",
        "        mp_r = {var: i for i, var in enumerate(r_expanded)}\n",
        "        return mp_l, mp_r\n",
        "\n",
        "    def expand_left_and_right_sides(self, tensor: np.ndarray, l_tokens: List[str], r_tokens: List[str]) -> Tuple[List[str], List[str]]:\n",
        "        \"\"\"\n",
        "        Expand the left and right token lists, handling ellipsis and grouped dimensions.\n",
        "\n",
        "        Args:\n",
        "            tensor: The input numpy array.\n",
        "            l_tokens: The tokenized left side of the pattern.\n",
        "            r_tokens: The tokenized right side of the pattern.\n",
        "\n",
        "        Returns:\n",
        "            A tuple containing two lists:\n",
        "            - l_expanded: The expanded list of tokens from the left side.\n",
        "            - r_expanded: The expanded list of tokens from the right side.\n",
        "\n",
        "        Note:\n",
        "            This function handles ellipsis (...) by replacing it with named dimensions\n",
        "            and expands grouped dimensions like (h w) into separate dimensions.\n",
        "        \"\"\"\n",
        "        n_ellipsis = len(tensor.shape) - (len(l_tokens) - sum(1 for t in l_tokens if t == '...'))\n",
        "        ellipsis_vars = [f'__ellipsis{i}' for i in range(n_ellipsis)]\n",
        "\n",
        "        def expand_tokens(tokens: List[str]) -> List[str]:\n",
        "            \"\"\"\n",
        "            Expand a list of tokens, handling ellipsis and grouped dimensions.\n",
        "\n",
        "            Args:\n",
        "                tokens: A list of token strings from the pattern.\n",
        "\n",
        "            Returns:\n",
        "                A list of expanded token strings.\n",
        "            \"\"\"\n",
        "            expanded = []\n",
        "            for token in tokens:\n",
        "                if token == '...':\n",
        "                    expanded.extend(ellipsis_vars)\n",
        "                elif token.startswith('('):\n",
        "                    expanded.extend(token[1:-1].split())\n",
        "                else:\n",
        "                    expanded.append(token)\n",
        "            return expanded\n",
        "\n",
        "        l_expanded = expand_tokens(l_tokens)\n",
        "        r_expanded = expand_tokens(r_tokens)\n",
        "        return l_expanded, r_expanded\n",
        "\n",
        "    def get_brackets(self, r_tokens: List[str], mp_r: Dict[str, int]) -> List[List[int]]:\n",
        "        \"\"\"\n",
        "        Extract the bracketed (grouped) dimensions from the right side tokens.\n",
        "\n",
        "        Args:\n",
        "            r_tokens: The tokenized right side of the pattern.\n",
        "            mp_r: The mapping from dimension names to indices in the expanded right tokens.\n",
        "\n",
        "        Returns:\n",
        "            A list of lists, where each inner list contains the indices of dimensions that\n",
        "            are grouped together in the output tensor.\n",
        "        \"\"\"\n",
        "        brackets = []\n",
        "        for token in r_tokens:\n",
        "            if token.startswith('('):\n",
        "                grouped = token[1:-1].split()\n",
        "                indices = [mp_r[var] for var in grouped]\n",
        "                brackets.append(indices)\n",
        "        return brackets\n",
        "\n",
        "    def get_resulting_array(self, tensor: np.ndarray, l_tokens: List[str], r_tokens: List[str],\n",
        "                           l_expanded: List[str], r_expanded: List[str], brackets: List[List[int]],\n",
        "                           **axes_lengths: Dict[str, int]) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Perform the actual tensor transformation based on the parsed pattern.\n",
        "\n",
        "        Args:\n",
        "            tensor: The input numpy array.\n",
        "            l_tokens: The tokenized left side of the pattern.\n",
        "            r_tokens: The tokenized right side of the pattern.\n",
        "            l_expanded: The expanded list of tokens from the left side.\n",
        "            r_expanded: The expanded list of tokens from the right side.\n",
        "            brackets: The list of indices representing grouped dimensions in output.\n",
        "            **axes_lengths: Keyword arguments specifying the sizes of dimensions.\n",
        "\n",
        "        Returns:\n",
        "            The transformed numpy array.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If there are issues with dimension sizes, incompatible shapes,\n",
        "                       or insufficient information to determine dimension sizes.\n",
        "        \"\"\"\n",
        "        reshape_dims = []\n",
        "        array_dims = list(tensor.shape)\n",
        "        n_ellipsis = len(tensor.shape) - (len(l_tokens) - sum(1 for t in l_tokens if t == '...'))\n",
        "        ellipsis_vars = [f'ellipsis_{i}' for i in range(n_ellipsis)]\n",
        "\n",
        "        # Process left side tokens for reshape operation\n",
        "        for token in l_tokens:\n",
        "            if token == '...':\n",
        "                reshape_dims.extend(array_dims[:n_ellipsis])\n",
        "                array_dims = array_dims[n_ellipsis:]\n",
        "            elif token.startswith('('):\n",
        "                grouped = token[1:-1].split()\n",
        "                total = array_dims.pop(0)\n",
        "                provided = {}\n",
        "                missing = []\n",
        "                for var in grouped:\n",
        "                    if var in axes_lengths:\n",
        "                        provided[var] = axes_lengths[var]\n",
        "                    else:\n",
        "                        missing.append(var)\n",
        "                if len(missing) > 1:\n",
        "                    raise ValueError(f\"Missing sizes for {missing} in group {grouped}\")\n",
        "                known_prod = math.prod(provided.values(), start=1)\n",
        "                if missing:\n",
        "                    miss = missing[0]\n",
        "                    if total % known_prod != 0:\n",
        "                        raise ValueError(f\"Cannot split {total} into {grouped} with provided sizes {provided}\")\n",
        "                    provided[miss] = total // known_prod\n",
        "                if math.prod(provided.values()) != total:\n",
        "                    raise ValueError(f\"Product of {grouped} sizes does not match {total}\")\n",
        "                reshape_dims.extend(provided[var] for var in grouped)\n",
        "            else:\n",
        "                if token in axes_lengths:\n",
        "                    expected_size = axes_lengths[token]\n",
        "                    actual_size = array_dims.pop(0)\n",
        "                    if expected_size != actual_size:\n",
        "                        raise ValueError(f\"Expected size {expected_size} for axis '{token}', got {actual_size}\")\n",
        "                    reshape_dims.append(expected_size)\n",
        "                else:\n",
        "                    reshape_dims.append(array_dims.pop(0))\n",
        "\n",
        "        # Identify variables that exist in both left and right sides\n",
        "        left_vars_set = set(l_expanded)\n",
        "        existing_vars_in_right = [var for var in r_expanded if var in left_vars_set]\n",
        "        new_vars_in_right = [var for var in r_expanded if var not in left_vars_set]\n",
        "\n",
        "        # Check that all new dimensions in right side have specified lengths\n",
        "        for var in new_vars_in_right:\n",
        "            if var not in axes_lengths:\n",
        "                raise ValueError(f\"New axis '{var}' requires a size in axes_lengths\")\n",
        "\n",
        "        # Create mapping and determine new order for transposition\n",
        "        mp_l, _ = self.create_idx_mapping(l_expanded, [])\n",
        "        new_order = [mp_l[var] for var in existing_vars_in_right]\n",
        "        left_only_vars = [var for var in l_expanded if var not in existing_vars_in_right]\n",
        "        new_order += [mp_l[var] for var in left_only_vars]\n",
        "\n",
        "        # Reshape and transpose\n",
        "        try:\n",
        "            b = tensor.reshape(reshape_dims)\n",
        "            b = np.transpose(b, new_order)\n",
        "        except ValueError as e:\n",
        "            raise ValueError(f\"Failed to reshape or transpose: {e}\")\n",
        "\n",
        "        # Handle new dimensions that need to be inserted\n",
        "        inserted_positions = []\n",
        "        for i, var in enumerate(r_expanded):\n",
        "            if var in new_vars_in_right:\n",
        "                size = axes_lengths[var]\n",
        "                b = np.expand_dims(b, axis=i)\n",
        "                b = np.repeat(b, size, axis=i)\n",
        "                inserted_positions.append(i)\n",
        "\n",
        "        # Handle dimensions that are in left but not right (to be squeezed out)\n",
        "        left_only_positions = list(range(len(existing_vars_in_right), len(existing_vars_in_right) + len(left_only_vars)))\n",
        "        for pos in inserted_positions:\n",
        "            for j in range(len(left_only_positions)):\n",
        "                if left_only_positions[j] >= pos:\n",
        "                    left_only_positions[j] += 1\n",
        "\n",
        "        for pos in reversed(sorted(left_only_positions)):\n",
        "            if b.shape[pos] != 1:\n",
        "                raise ValueError(f\"Dimension {pos} must be 1 to squeeze, but is {b.shape[pos]}\")\n",
        "            b = np.squeeze(b, axis=pos)\n",
        "\n",
        "        # Handle bracketed (grouped) dimensions in the right side\n",
        "        offset = 0\n",
        "        for group in brackets:\n",
        "            group = [idx - offset for idx in group]\n",
        "            start = group[0]\n",
        "            end = group[-1]\n",
        "            merged_size = np.prod(b.shape[start:end+1])\n",
        "            new_shape = list(b.shape[:start]) + [merged_size] + list(b.shape[end+1:])\n",
        "            b = b.reshape(new_shape)\n",
        "            offset += (end - start)\n",
        "\n",
        "        return b\n",
        "\n",
        "    def rearrange(self, tensor: np.ndarray, pattern: str, **axes_lengths: int) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Rearrange a tensor according to the provided einops-like pattern.\n",
        "\n",
        "        Args:\n",
        "            tensor: The input numpy array to rearrange.\n",
        "            pattern: A string in the format 'left -> right' that specifies how to transform the tensor.\n",
        "                    Where 'left' describes the input tensor dimensions and 'right' describes the output.\n",
        "            **axes_lengths: Keyword arguments specifying the sizes for any new dimensions or\n",
        "                           dimensions that need explicit size specification.\n",
        "\n",
        "        Returns:\n",
        "            The rearranged numpy array according to the provided pattern.\n",
        "\n",
        "        Examples:\n",
        "            >>> x = np.random.randn(3, 4, 5)  # shape (3, 4, 5)\n",
        "            >>> einops = Einops()\n",
        "            >>> y = einops.rearrange(x, 'a b c -> b a c')  # Transpose axes 0 and 1\n",
        "            >>> y.shape\n",
        "            (4, 3, 5)\n",
        "\n",
        "            >>> # Split dimension 'b' into 'h' and 'w'\n",
        "            >>> z = einops.rearrange(x, 'a (h w) c -> a h w c', h=2)\n",
        "            >>> z.shape\n",
        "            (3, 2, 2, 5)\n",
        "        \"\"\"\n",
        "        l_tokens, r_tokens = self.parse_lr(pattern)\n",
        "        l_expanded, r_expanded = self.expand_left_and_right_sides(tensor, l_tokens, r_tokens)\n",
        "        mp_r = {var: i for i, var in enumerate(r_expanded)}\n",
        "        brackets = self.get_brackets(r_tokens, mp_r)\n",
        "        result = self.get_resulting_array(tensor, l_tokens, r_tokens, l_expanded, r_expanded, brackets, **axes_lengths)\n",
        "        return result"
      ],
      "metadata": {
        "id": "WoRF9je81nRr"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "einops = EinopsManan()"
      ],
      "metadata": {
        "id": "Qpwcd3MEpNDO"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment test cases"
      ],
      "metadata": {
        "id": "ixz9ql6JzlQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(3, 4)\n",
        "result = einops.rearrange(x, 'h w -> w h')\n",
        "print(result.shape)\n",
        "\n",
        "x = np.random.rand(12, 10)\n",
        "result = einops.rearrange(x, '(h w) c -> h w c', h=3)\n",
        "print(result.shape)\n",
        "\n",
        "x = np.random.rand(3, 4, 5)\n",
        "result = einops.rearrange(x, 'a b c -> (a b) c')\n",
        "print(result.shape)\n",
        "\n",
        "x = np.random.rand(3, 1, 5)\n",
        "result = einops.rearrange(x, 'a 1 c -> a b c', b=4)\n",
        "print(result.shape)\n",
        "\n",
        "x = np.random.rand(2, 3, 4, 5)\n",
        "result = einops.rearrange(x, '... h w -> ... (h w)')\n",
        "print(result.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6C9_-jev5GR",
        "outputId": "9fbe9e40-4415-44c4-f0ed-278f9ab1a2f8"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 3)\n",
            "(3, 4, 10)\n",
            "(12, 5)\n",
            "(3, 4, 5)\n",
            "(2, 3, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test cases:"
      ],
      "metadata": {
        "id": "KWamzkaQznbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(2, 3, 4)\n",
        "result = einops.rearrange(x, '... -> ...')\n",
        "print(result.shape)  # (2,3,4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNmXqMXewHQQ",
        "outputId": "0d5bca46-487f-464e-d27e-98d243cab364"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 3, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(2, 2, 5)\n",
        "result = einops.rearrange(x, 'a b c -> (a b) c')\n",
        "print(result.shape)  # (4, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRorpoL0zvhl",
        "outputId": "3c94acdb-05f1-49ae-a7cf-3a109adf4619"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.randn(4,5)\n",
        "x = einops.rearrange(result, '(a b) c -> a b c', a=2)\n",
        "print(x.shape)  # (2, 2, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbKyLd4IxbmI",
        "outputId": "13a6e143-bdd2-4182-d861-d95560947657"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 2, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(2, 3, 4)\n",
        "result = einops.rearrange(x, 'a b c -> c b a')\n",
        "print(result.shape)  # (4, 3, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjybbZciz5Gk",
        "outputId": "0b715dc3-2295-4dfa-ddab-76fe8c015096"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 3, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(2, 3, 4)\n",
        "result = einops.rearrange(x, '... c -> c ...')\n",
        "print(result.shape)  # (4, 2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qam29CGfz7gO",
        "outputId": "4d259a5d-9d8d-461e-c6ca-5c687c7c4adb"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(2, 6, 5)\n",
        "result = einops.rearrange(x, 'b (h w) c -> (c h) b w', h=2)\n",
        "print(result.shape)  # (10, 2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF-EwWGFz-Aa",
        "outputId": "83d963c3-578a-4db1-b222-86b46dc7fdef"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(2, 3, 4, 5)\n",
        "result = einops.rearrange(x, 'a b c d -> (a b) (c d)')\n",
        "print(result.shape)  # (6, 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYo595pm0AwW",
        "outputId": "8c6e7756-a25e-4182-b189-d954ca171a45"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(5)\n",
        "result = einops.rearrange(x, 'c -> t c l', t=1, l=1 )\n",
        "print(result.shape)  # (1, 5, 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXHcgSsi0CZq",
        "outputId": "a5c39ce7-88c0-45f8-a9d8-bced053ffc82"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 5, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(2, 3, 4, 5)\n",
        "result = einops.rearrange(x, '... (h w) -> ... h w', h=2)\n",
        "print(result.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "opVm1clP0WO0",
        "outputId": "f03cd811-6880-4309-d023-34d6fc89ea3a"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot split 5 into ['h', 'w'] with provided sizes {'h': 2}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-125-5b3b1f35e50f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meinops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'... (h w) -> ... h w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-114-6d508476a796>\u001b[0m in \u001b[0;36mrearrange\u001b[0;34m(self, tensor, pattern, **axes_lengths)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mmp_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_expanded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mbrackets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_brackets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmp_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_resulting_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_expanded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_expanded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrackets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maxes_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-114-6d508476a796>\u001b[0m in \u001b[0;36mget_resulting_array\u001b[0;34m(self, tensor, l_tokens, r_tokens, l_expanded, r_expanded, brackets, **axes_lengths)\u001b[0m\n\u001b[1;32m    159\u001b[0m                     \u001b[0mmiss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mknown_prod\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cannot split {total} into {grouped} with provided sizes {provided}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m                     \u001b[0mprovided\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmiss\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mknown_prod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot split 5 into ['h', 'w'] with provided sizes {'h': 2}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(2, 6, 8)\n",
        "result = einops.rearrange(x, 'b (h1 h2) (w1 w2) -> b h1 w1 h2 w2', h1=2, w1=2)\n",
        "print(result.shape)  # (2, 2, 2, 3, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iEhv0BC0bq0",
        "outputId": "727b57c0-bd03-49d7-a0b8-7944898d249c"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 2, 2, 3, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(24, 8)\n",
        "result = einops.rearrange(x, '(a b c) d -> c b a d', a=2, b=3)\n",
        "print(result.shape)   # (4, 3, 2, 8)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUhlzqw30fx8",
        "outputId": "9c1f029f-4e27-41be-c1b6-9bb71011f729"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 3, 2, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "87tyyTeT3CXS"
      },
      "execution_count": 127,
      "outputs": []
    }
  ]
}